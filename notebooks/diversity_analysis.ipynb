{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCaJS8l6bVUd"
   },
   "source": [
    "Step 1 - Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2812,
     "status": "ok",
     "timestamp": 1613022068512,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "9bBYu120mKtm",
    "outputId": "48a21834-c908-438f-c754-13e4aea67015"
   },
   "outputs": [],
   "source": [
    "%pip install IPython\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install seaborn\n",
    "%pip install scipy\n",
    "\n",
    "from IPython import get_ipython\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFiLjqTDYzFK"
   },
   "source": [
    "Step 2 - Load and read your data file\n",
    "- pyTCR accepts a single `.csv` file that should contain all the samples.\n",
    "  - The following cell attempts to detect whether you are running the notebook in a Google Colab cloud environment or in a local environment, and then loads the data at the specified path.\n",
    "- The `filePath` variable in the following code cell should be changed to the location of your file. The following options are supported:\n",
    "  1. A `filePath` from Google Drive (to run on a cloud environment)\n",
    "  2. A `filePath` from your local computer (to run on a local environment, other cloud environments should work as expected)\n",
    "- Adjust the `optional_fields` according to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "isInGoogle = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if isInGoogle:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your data in Google Drive or locally\n",
    "filePath = \"../combined_data.csv\" # or \"/content/drive/MyDrive/combined_data.csv\"\n",
    "\n",
    "df = pd.read_csv(filePath, low_memory=False, engine=\"c\")\n",
    "\n",
    "optional_fields = ['hospitalized']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TM_0L9NMm4J8"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with reads count for each sample\n",
    "df_reads = df.groupby(['sample', 'hospitalized']).agg(\n",
    "    {'#count': 'sum'}).reset_index().rename(columns={'#count': \"count\"})\n",
    "\n",
    "# Create a dataframe with clonotype count for each sample\n",
    "df_diversity = df.groupby(['sample', 'hospitalized'], sort=False).size().reset_index(name='clonotype_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 6502,
     "status": "ok",
     "timestamp": 1612909183469,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "4s64SXhQBxEL",
    "outputId": "18a563e1-8d7b-459a-d898-6128d8cf9c26"
   },
   "outputs": [],
   "source": [
    "# Add clonotype count of each sample as a column to create a new dataframe\n",
    "df = pd.merge(df, df_diversity, on=['sample', 'hospitalized'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs6F2zfmmogx"
   },
   "source": [
    "Diversity analysis 1 - Shannon-Wiener index [shannon_wiener_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgHqKRKymg79"
   },
   "outputs": [],
   "source": [
    "# Calculation step 1\n",
    "df['shannon_index'] = -(df['freq']*np.log(df['freq']))\n",
    "\n",
    "# Calculation step 2\n",
    "df_shannon = df.groupby(['sample', 'hospitalized']).agg(\n",
    "    {'shannon_index': 'sum'}).reset_index().rename(columns={'': \"shannon_index\"})\n",
    "\n",
    "# Calculation step 3, Shannon-Wienex index is shown in the shannon_wiener_index column\n",
    "df_shannon['shannon_wiener_index'] = np.exp(df_shannon['shannon_index'])\n",
    "df_shannon_index = df_shannon[['sample', 'hospitalized', 'shannon_wiener_index']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyT94i0vmwRT"
   },
   "source": [
    "Diversity analysis 2 - Normalized Shannon-Wiener index [normalized_shannon_wiener_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfM-LCoDmwxH"
   },
   "outputs": [],
   "source": [
    "# Calculation step 1 - merge df_shannon and df_diversity (which contains clonotype counts)\n",
    "df_shannon = pd.merge(df_shannon, df_diversity, on=[\n",
    "                      'sample', 'hospitalized'])\n",
    "\n",
    "# Calculation step 2 - calculate normalized Shannon-Wienex index, it is shown in the normalized_shannon_wiener_index column\n",
    "df_shannon['normalized_shannon_wiener_index'] = df_shannon['shannon_index'] / \\\n",
    "    np.log(df_shannon['clonotype_count'])\n",
    "\n",
    "df_norm_shannon = df_shannon[['sample', 'hospitalized','shannon_wiener_index', 'normalized_shannon_wiener_index']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4V8KvFgQnDfR"
   },
   "source": [
    "Diversity analysis 3 - Inverse Simpson index [inverse_simpson_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfL2ttlAnEXi"
   },
   "outputs": [],
   "source": [
    "# Calculation step 1\n",
    "df['simpson_index'] = (df['freq']**2)\n",
    "\n",
    "# Calculation step 2\n",
    "df_simpson = df.groupby(['sample', 'hospitalized']).agg(\n",
    "    {'simpson_index': 'sum'}).reset_index().rename(columns={'': \"simpson_index\"})\n",
    "\n",
    "# Calculation step 3, Inverse Simpson index is shown in the inverse_simpson_index column\n",
    "df_simpson['inverse_simpson_index'] = 1/df_simpson['simpson_index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OG6dxToxMP_"
   },
   "source": [
    "Diversity analysis 4 - Gini Simpson index [gini_simpson_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEaKFHevxRx6"
   },
   "outputs": [],
   "source": [
    "df_simpson['gini_simpson_index'] = 1-df_simpson['simpson_index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtIH43jnrvLz"
   },
   "source": [
    "Diversity analysis 5 - D50 index [D50_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZITswYRT4HM"
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe for storing results\n",
    "df_D50 = pd.DataFrame()\n",
    "\n",
    "# Create a list of the sample names\n",
    "samples = set(df['sample'])\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    # Store the rows related to the sample\n",
    "    df_temp = df.loc[df['sample'] == sample]\n",
    "\n",
    "    # Sort the sample clonotypes by frequency in descending order\n",
    "    df_temp = df_temp.sort_values(by='freq', ascending=False)\n",
    "\n",
    "    # Create a column to store the order\n",
    "    df_temp['clonotype_number'] = np.arange(df_temp.shape[0])+1\n",
    "\n",
    "    # Compute and store the cumulative sum of the frequencies\n",
    "    df_temp['accum_freq'] = df_temp['freq'].cumsum()\n",
    "\n",
    "    # Find out the first accumulated frequency that is above 50%\n",
    "    df_temp = df_temp.loc[(df_temp['accum_freq'] >= 0.5)\n",
    "                          & (df_temp['accum_freq'] <= 0.6)]\n",
    "    df_temp = df_temp.head(1)\n",
    "\n",
    "    # Calculate D50 index and store in the result dataframe\n",
    "    df_temp = df_temp.head(1)\n",
    "    df_temp['D50_index'] = df_temp['clonotype_number'] / \\\n",
    "        df_temp['clonotype_count']*100\n",
    "    df_D50 = pd.concat([df_D50, df_temp])\n",
    "\n",
    "df_D50 = df_D50[['sample', 'hospitalized', 'D50_index']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e4Vj3PQiSpp"
   },
   "source": [
    "Diversity analysis 6 - Chao1 estimate [chao1] and standard deviation [chao1_SD]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIo-FtKeMXkb"
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe for storing results\n",
    "df_chao1 = pd.DataFrame()\n",
    "\n",
    "# Get the columns needed for calculation from df\n",
    "df1 = df[['sample', '#count', 'clonotype_count', 'hospitalized']]\n",
    "\n",
    "# Create a list of the sample names\n",
    "samples = set(df1['sample'])\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    # Store the rows related to the sample\n",
    "    df_temp = df1.loc[df1['sample'] == sample]\n",
    "\n",
    "    # Count singleton in the sample\n",
    "    singleton = len(df_temp.loc[df_temp['#count'] == 1])\n",
    "\n",
    "    # Count doubleton in the sample\n",
    "    doubleton = len(df_temp.loc[df_temp['#count'] == 2])\n",
    "\n",
    "    # Calculate Chao1 estimate\n",
    "    chao1 = int(df_temp['clonotype_count'].values[0]) + \\\n",
    "        ((singleton * (singleton-1))/(2*(doubleton+1)))\n",
    "    df_temp['chao1'] = chao1\n",
    "\n",
    "    # Calculate Chao1 estimate standard deviation\n",
    "    step1 = 1/4*((singleton/doubleton)**4)\n",
    "    step2 = (singleton/doubleton)**3\n",
    "    step3 = 1/2*((singleton/doubleton)**2)\n",
    "    step4 = doubleton * (step1+step2+step3)\n",
    "    df_temp['chao1_SD'] = step4**(1/2)\n",
    "\n",
    "    # Store the results in the result dataframe\n",
    "    df_chao1 = pd.concat([df_chao1, df_temp], axis=0, sort=False)\n",
    "\n",
    "    # Remove the duplicates results in the result dataframe\n",
    "    df_chao1 = df_chao1[['sample', 'hospitalized', 'chao1', 'chao1_SD']]\n",
    "    df_chao1 = df_chao1.drop_duplicates(subset=['sample'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PV7hqBMDAVsf"
   },
   "source": [
    "Diversity analysis 7 - Gini coefficient [gini_coefficient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 44834,
     "status": "ok",
     "timestamp": 1608191533777,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "XKfpM0-xTf3Z",
    "outputId": "2efb5548-e27f-4ad7-94f9-30538d3509f7"
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe for storing results\n",
    "df_gini = pd.DataFrame()\n",
    "\n",
    "# Create a list of the sample names\n",
    "samples = set(df['sample'])\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    # Store the rows related to the sample\n",
    "    df_temp = df.loc[df['sample'] == sample]\n",
    "\n",
    "    def gini(list_of_values):\n",
    "        sorted_list = sorted(list_of_values)\n",
    "        height, area = 0, 0\n",
    "        for value in sorted_list:\n",
    "            height += value\n",
    "            area += height - value / 2.\n",
    "        fair_area = height * len(list_of_values) / 2.\n",
    "        return (fair_area - area) / fair_area\n",
    "\n",
    "    # Calculate gini coefficient\n",
    "    df_temp['gini_coefficient'] = gini(df_temp['freq'])\n",
    "\n",
    "    # Store the results in the result dataframe\n",
    "    df_gini = pd.concat([df_gini, df_temp], sort=False)\n",
    "\n",
    "    # Remove the duplicates results in the result dataframe\n",
    "    df_gini = df_gini[['sample', 'hospitalized', 'gini_coefficient']]\n",
    "    df_gini = df_gini.drop_duplicates(subset=['sample'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDtm47SLrtsY"
   },
   "source": [
    "Diversity analysis 8 - Summary table for the diversity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-G01YeresGRR"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that combines all the diversity analysis\n",
    "dfs = [df_norm_shannon, df_simpson, df_D50, df_chao1, df_gini]\n",
    "\n",
    "df_combined = pd.merge(dfs[0], dfs[1], left_on=['sample', 'hospitalized'], right_on=[\n",
    "                       'sample', 'hospitalized'], how='outer')\n",
    "\n",
    "for d in dfs[2:]:\n",
    "    df_combined = pd.merge(df_combined, d, left_on=['sample', 'hospitalized'], right_on=[\n",
    "                           'sample', 'hospitalized'], how='outer')\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LQwMFNxsF15"
   },
   "source": [
    "Diversity analysis 9 - Statistical analysis of diversity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5e94C_rtEN4"
   },
   "source": [
    "Diversity 9.1 - Mean or median of diversity metrics among groups \n",
    "1.   if the dataset is normally distributed, calculate mean\n",
    "2.   if the dataset is not normally distributed, calculate median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1608192909181,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "8GWc40-itn0G",
    "outputId": "b17476bc-02e8-44f4-fb01-006ccec40759"
   },
   "outputs": [],
   "source": [
    "# Calculate the mean among two groups\n",
    "df_combined_mean = pd.DataFrame(columns=['hospitalized'])\n",
    "\n",
    "for column in df_combined[['shannon_wiener_index', 'normalized_shannon_wiener_index', 'inverse_simpson_index', 'gini_simpson_index', 'D50_index', 'chao1', 'gini_coefficient']]:\n",
    "    df_temp = df_combined.groupby('hospitalized')[\n",
    "        column].mean().reset_index()\n",
    "    df_combined_mean = pd.merge(df_combined_mean, df_temp, on=[\n",
    "                                'hospitalized'], how='right')\n",
    "\n",
    "df_combined_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1608192999614,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "s2AgGAImxOp9",
    "outputId": "709a1359-2bc3-45c8-c657-5c768b470165",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the median among two groups\n",
    "df_combined_median = pd.DataFrame(columns=['hospitalized'])\n",
    "for column in df_combined[['shannon_wiener_index', 'normalized_shannon_wiener_index', 'inverse_simpson_index', 'gini_simpson_index', 'D50_index', 'chao1', 'gini_coefficient']]:\n",
    "    df_temp = df_combined.groupby('hospitalized')[\n",
    "        column].median().reset_index()\n",
    "    df_combined_median = pd.merge(df_combined_median, df_temp, on=[\n",
    "                                  'hospitalized'], how='right')\n",
    "    \n",
    "df_combined_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFd5BVWlDoq_"
   },
   "source": [
    "Diversity analysis 9.2 - Test if the certain diversity metric is normally distributed \n",
    "1.   the null hypothesis here is normality \n",
    "2.   if the p value is greater than 0.05, we cannot reject the null hypothesis (it is a normal distribution). If the p value is smaller than 0.05, we reject the null hypothesis (it is not a normal distribution)\n",
    "3.   change the \"shannon_wiener_index\" to other metrics that you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1608191685966,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "3Ar-jp29C83I",
    "outputId": "8000d53a-4283-4da2-96a8-bcef9c5d4eee"
   },
   "outputs": [],
   "source": [
    "x = stats.normaltest(df_combined['shannon_wiener_index'])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f32EBKhih6q2"
   },
   "source": [
    "Diversity analysis 9.3 - Stats test\n",
    "1.  if the dataset is normally distributed, use t-test (stats.ttest_ind)\n",
    "\n",
    "*   change the group1, group2 to the groups/samples that you are interested in\n",
    "*   change the \"shannon_wiener_index\" to other metrics that you are interested in\n",
    "\n",
    "2.  if the dataset is not normally distributed, use Wilcoxon rank-sum test (stats.ranksums)\n",
    "*   change the group1, group2 to the groups/samples that you are interested in\n",
    "*   change the \"shannon_wiener_index\" to other metrics that you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1608193033024,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "eB5ukA4oilsh",
    "outputId": "7a57236a-ea86-45ab-a417-126c03f6e0fb"
   },
   "outputs": [],
   "source": [
    "df_group1 = df_combined[df_combined['hospitalized'] == True]\n",
    "df_group2 = df_combined[df_combined['hospitalized'] == False]\n",
    "\n",
    "stats.ranksums(df_group1['shannon_wiener_index'],df_group2['shannon_wiener_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBGAPH1wU-k0"
   },
   "source": [
    "Diversity analysis 10 - Visualization\n",
    "1.   change x = 'hospitalized' to the diversity index that you are interested\n",
    "2.   change y = 'shannon_wiener_index' to the index that you desire\n",
    "3.   change the violin plot (sns.violinplot) to the plot type that you are interested in, includes strip plot (sns.stripplot), swarm plot (sns.swarmplot), box plot (sns.boxplot), boxen plot (sns.boxenplot), point plot (sns.pointplot), and bar plot (sns.barplot)\n",
    "4.   set x label to the feature that you choose\n",
    "5.   set y label to the index that you choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1606778797132,
     "user": {
      "displayName": "Kerui Peng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhCFbNNQavDfyVFYGThBoWptUPcEdIkBKjW1JK6=s64",
      "userId": "00454648627764987552"
     },
     "user_tz": 480
    },
    "id": "wtOHFMS3U6-V",
    "outputId": "76c75f98-35d2-4a44-b26a-49f3717fbeee"
   },
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax = sns.barplot(x='hospitalized',\n",
    "                 y='shannon_wiener_index', data=df_combined)\n",
    "\n",
    "ax.set_xlabel('hospitalized', fontsize=20)\n",
    "ax.set_ylabel('shannon_wiener_index', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Diversity analysis_COVID.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
